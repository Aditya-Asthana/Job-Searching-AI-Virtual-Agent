{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 15589,
     "status": "ok",
     "timestamp": 1733768722876,
     "user": {
      "displayName": "Aditya Asthana",
      "userId": "16260857847002908036"
     },
     "user_tz": 480
    },
    "id": "JqyCY-VRlSVO",
    "outputId": "a6c0e064-3d56-44ee-e680-371d8c2db852"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[?25l   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/345.0 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K   \u001b[91m━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[91m╸\u001b[0m\u001b[90m━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m204.8/345.0 kB\u001b[0m \u001b[31m5.9 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m345.0/345.0 kB\u001b[0m \u001b[31m6.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25h\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
      "jupyter-server 1.24.0 requires anyio<4,>=3.1.0, but you have anyio 4.7.0 which is incompatible.\n",
      "tensorflow 2.17.1 requires protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<5.0.0dev,>=3.20.3, but you have protobuf 5.29.1 which is incompatible.\u001b[0m\u001b[31m\n",
      "\u001b[0m"
     ]
    }
   ],
   "source": [
    "!pip install openai==1.55.3 httpx==0.27.2 --force-reinstall --quiet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "DChcaYi1lmrk"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "os.kill(os.getpid(), 9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 28611,
     "status": "ok",
     "timestamp": 1733768760884,
     "user": {
      "displayName": "Aditya Asthana",
      "userId": "16260857847002908036"
     },
     "user_tz": 480
    },
    "id": "qVkwM6vriI4i",
    "outputId": "7b687ca4-8a5a-4082-c6a5-d986bf0d1a55"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[?25l   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/50.7 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m50.7/50.7 kB\u001b[0m \u001b[31m2.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25h"
     ]
    }
   ],
   "source": [
    "!pip install -U langchain-community -q\n",
    "!pip install --upgrade openai langchain langchain-openai -q\n",
    "!pip install chromadb -q\n",
    "!pip install tiktoken -q\n",
    "# !pip install openai==1.55.3 httpx==0.27.2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "executionInfo": {
     "elapsed": 232,
     "status": "ok",
     "timestamp": 1733769161431,
     "user": {
      "displayName": "Aditya Asthana",
      "userId": "16260857847002908036"
     },
     "user_tz": 480
    },
    "id": "2v62rXvMh1Ug"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import glob\n",
    "import json\n",
    "from langchain.embeddings.openai import OpenAIEmbeddings\n",
    "from langchain.vectorstores import Chroma\n",
    "from langchain.chat_models import ChatOpenAI\n",
    "from langchain.text_splitter import CharacterTextSplitter\n",
    "from langchain.docstore.document import Document"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 810,
     "status": "ok",
     "timestamp": 1733768764452,
     "user": {
      "displayName": "Aditya Asthana",
      "userId": "16260857847002908036"
     },
     "user_tz": 480
    },
    "id": "bIR0xSwOh-xY",
    "outputId": "00b5c643-2ae4-4365-f953-a242911ba460"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
     ]
    }
   ],
   "source": [
    "# from google.colab import drive\n",
    "# drive.mount('/content/drive')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 225,
     "status": "ok",
     "timestamp": 1733770848340,
     "user": {
      "displayName": "Aditya Asthana",
      "userId": "16260857847002908036"
     },
     "user_tz": 480
    },
    "id": "tBqJdx2IiS2S"
   },
   "outputs": [],
   "source": [
    "import getpass\n",
    "os.environ[\"OPENAI_API_KEY\"] = getpass.getpass(\"Enter your OpenAI API key: \")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "executionInfo": {
     "elapsed": 262,
     "status": "ok",
     "timestamp": 1733770912556,
     "user": {
      "displayName": "Aditya Asthana",
      "userId": "16260857847002908036"
     },
     "user_tz": 480
    },
    "id": "WDMbm0XfioDW"
   },
   "outputs": [],
   "source": [
    "resume_folder = \"/content/drive/My Drive/Resume Chatbot/resumes\"\n",
    "\n",
    "json_paths = glob.glob(os.path.join(resume_folder, \"*.json\"))\n",
    "\n",
    "text_splitter = CharacterTextSplitter(\n",
    "    chunk_size=1000,\n",
    "    chunk_overlap=100\n",
    ")\n",
    "\n",
    "documents = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "executionInfo": {
     "elapsed": 122,
     "status": "ok",
     "timestamp": 1733770916020,
     "user": {
      "displayName": "Aditya Asthana",
      "userId": "16260857847002908036"
     },
     "user_tz": 480
    },
    "id": "nuLns79eizMH"
   },
   "outputs": [],
   "source": [
    "def create_resume_text(candidate):\n",
    "    name = candidate.get(\"name\", \"Unknown Candidate\")\n",
    "    profile = candidate.get(\"profile\", \"\")\n",
    "    skills = candidate.get(\"skills\", [])\n",
    "    education = candidate.get(\"education\", [])\n",
    "    experience = candidate.get(\"experience\", [])\n",
    "    projects = candidate.get(\"projects\", [])\n",
    "\n",
    "    skills_text = \"Skills: \" + \", \".join(skills) if skills else \"\"\n",
    "    education_text = \"Education:\\n\" + \"\\n\".join(education) if education else \"\"\n",
    "\n",
    "    experience_text = \"\"\n",
    "    if experience:\n",
    "        experience_text = \"Experience:\\n\"\n",
    "        for exp in experience:\n",
    "            exp_position = exp.get(\"position\", \"\")\n",
    "            exp_company = exp.get(\"company\", \"\")\n",
    "            exp_duration = exp.get(\"duration\", \"\")\n",
    "            exp_desc = exp.get(\"description\", [])\n",
    "            exp_desc_text = \"\\n\".join([f\"- {d}\" for d in exp_desc])\n",
    "            experience_text += f\"{exp_position} at {exp_company} ({exp_duration})\\n{exp_desc_text}\\n\\n\"\n",
    "\n",
    "    projects_text = \"\"\n",
    "    if projects:\n",
    "        projects_text = \"Projects:\\n\"\n",
    "        for proj in projects:\n",
    "            proj_title = proj.get(\"title\", \"\")\n",
    "            proj_desc = proj.get(\"description\", [])\n",
    "            proj_desc_text = \"\\n\".join([f\"- {d}\" for d in proj_desc])\n",
    "            projects_text += f\"{proj_title}:\\n{proj_desc_text}\\n\\n\"\n",
    "\n",
    "    full_text = f\"Name: {name}\\nProfile: {profile}\\n\\n{skills_text}\\n\\n{education_text}\\n\\n{experience_text}\\n{projects_text}\"\n",
    "    return full_text.strip()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 140,
     "status": "ok",
     "timestamp": 1733770918037,
     "user": {
      "displayName": "Aditya Asthana",
      "userId": "16260857847002908036"
     },
     "user_tz": 480
    },
    "id": "ZEvLEBk2i3RT",
    "outputId": "e6072869-1bbf-4c12-855e-e1d9a8ad6078"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Checking file: /content/drive/My Drive/Resume Chatbot/resumes/backend_engineer.json\n",
      "Loaded 5 candidates from /content/drive/My Drive/Resume Chatbot/resumes/backend_engineer.json\n",
      "Candidate Ethan Carter from /content/drive/My Drive/Resume Chatbot/resumes/backend_engineer.json: 1550 characters of resume text.\n",
      "Candidate Ethan Carter from /content/drive/My Drive/Resume Chatbot/resumes/backend_engineer.json: Created 2 chunks.\n",
      "Candidate Olivia Johnson from /content/drive/My Drive/Resume Chatbot/resumes/backend_engineer.json: 1459 characters of resume text.\n",
      "Candidate Olivia Johnson from /content/drive/My Drive/Resume Chatbot/resumes/backend_engineer.json: Created 2 chunks.\n",
      "Candidate Liam Brooks from /content/drive/My Drive/Resume Chatbot/resumes/backend_engineer.json: 1122 characters of resume text.\n",
      "Candidate Liam Brooks from /content/drive/My Drive/Resume Chatbot/resumes/backend_engineer.json: Created 2 chunks.\n",
      "Candidate Sophia Patel from /content/drive/My Drive/Resume Chatbot/resumes/backend_engineer.json: 967 characters of resume text.\n",
      "Candidate Sophia Patel from /content/drive/My Drive/Resume Chatbot/resumes/backend_engineer.json: Created 1 chunks.\n",
      "Candidate Mason White from /content/drive/My Drive/Resume Chatbot/resumes/backend_engineer.json: 1045 characters of resume text.\n",
      "Candidate Mason White from /content/drive/My Drive/Resume Chatbot/resumes/backend_engineer.json: Created 2 chunks.\n",
      "Checking file: /content/drive/My Drive/Resume Chatbot/resumes/frontend_engineer.json\n",
      "Loaded 5 candidates from /content/drive/My Drive/Resume Chatbot/resumes/frontend_engineer.json\n",
      "Candidate Emma Clark from /content/drive/My Drive/Resume Chatbot/resumes/frontend_engineer.json: 1455 characters of resume text.\n",
      "Candidate Emma Clark from /content/drive/My Drive/Resume Chatbot/resumes/frontend_engineer.json: Created 2 chunks.\n",
      "Candidate James Anderson from /content/drive/My Drive/Resume Chatbot/resumes/frontend_engineer.json: 1269 characters of resume text.\n",
      "Candidate James Anderson from /content/drive/My Drive/Resume Chatbot/resumes/frontend_engineer.json: Created 2 chunks.\n",
      "Candidate Sophia Martinez from /content/drive/My Drive/Resume Chatbot/resumes/frontend_engineer.json: 988 characters of resume text.\n",
      "Candidate Sophia Martinez from /content/drive/My Drive/Resume Chatbot/resumes/frontend_engineer.json: Created 1 chunks.\n",
      "Candidate Liam Walker from /content/drive/My Drive/Resume Chatbot/resumes/frontend_engineer.json: 1003 characters of resume text.\n",
      "Candidate Liam Walker from /content/drive/My Drive/Resume Chatbot/resumes/frontend_engineer.json: Created 2 chunks.\n",
      "Candidate Oliver Nguyen from /content/drive/My Drive/Resume Chatbot/resumes/frontend_engineer.json: 1001 characters of resume text.\n",
      "Candidate Oliver Nguyen from /content/drive/My Drive/Resume Chatbot/resumes/frontend_engineer.json: Created 2 chunks.\n",
      "Checking file: /content/drive/My Drive/Resume Chatbot/resumes/sales.json\n",
      "Loaded 5 candidates from /content/drive/My Drive/Resume Chatbot/resumes/sales.json\n",
      "Candidate Alex Morgan from /content/drive/My Drive/Resume Chatbot/resumes/sales.json: 1037 characters of resume text.\n",
      "Candidate Alex Morgan from /content/drive/My Drive/Resume Chatbot/resumes/sales.json: Created 2 chunks.\n",
      "Candidate Taylor Lee from /content/drive/My Drive/Resume Chatbot/resumes/sales.json: 1030 characters of resume text.\n",
      "Candidate Taylor Lee from /content/drive/My Drive/Resume Chatbot/resumes/sales.json: Created 2 chunks.\n",
      "Candidate Jordan Smith from /content/drive/My Drive/Resume Chatbot/resumes/sales.json: 956 characters of resume text.\n",
      "Candidate Jordan Smith from /content/drive/My Drive/Resume Chatbot/resumes/sales.json: Created 1 chunks.\n",
      "Candidate Sydney Brown from /content/drive/My Drive/Resume Chatbot/resumes/sales.json: 942 characters of resume text.\n",
      "Candidate Sydney Brown from /content/drive/My Drive/Resume Chatbot/resumes/sales.json: Created 1 chunks.\n",
      "Candidate Chris Nguyen from /content/drive/My Drive/Resume Chatbot/resumes/sales.json: 651 characters of resume text.\n",
      "Candidate Chris Nguyen from /content/drive/My Drive/Resume Chatbot/resumes/sales.json: Created 1 chunks.\n",
      "Checking file: /content/drive/My Drive/Resume Chatbot/resumes/finance.json\n",
      "Loaded 5 candidates from /content/drive/My Drive/Resume Chatbot/resumes/finance.json\n",
      "Candidate Michael Davis from /content/drive/My Drive/Resume Chatbot/resumes/finance.json: 1586 characters of resume text.\n",
      "Candidate Michael Davis from /content/drive/My Drive/Resume Chatbot/resumes/finance.json: Created 2 chunks.\n",
      "Candidate Sophia Johnson from /content/drive/My Drive/Resume Chatbot/resumes/finance.json: 1482 characters of resume text.\n",
      "Candidate Sophia Johnson from /content/drive/My Drive/Resume Chatbot/resumes/finance.json: Created 2 chunks.\n",
      "Candidate Ethan Miller from /content/drive/My Drive/Resume Chatbot/resumes/finance.json: 1075 characters of resume text.\n",
      "Candidate Ethan Miller from /content/drive/My Drive/Resume Chatbot/resumes/finance.json: Created 2 chunks.\n",
      "Candidate Emily Davis from /content/drive/My Drive/Resume Chatbot/resumes/finance.json: 1106 characters of resume text.\n",
      "Candidate Emily Davis from /content/drive/My Drive/Resume Chatbot/resumes/finance.json: Created 2 chunks.\n",
      "Candidate Liam Harris from /content/drive/My Drive/Resume Chatbot/resumes/finance.json: 1140 characters of resume text.\n",
      "Candidate Liam Harris from /content/drive/My Drive/Resume Chatbot/resumes/finance.json: Created 2 chunks.\n",
      "Checking file: /content/drive/My Drive/Resume Chatbot/resumes/general_engineer.json\n",
      "Loaded 5 candidates from /content/drive/My Drive/Resume Chatbot/resumes/general_engineer.json\n",
      "Candidate Daniel Roberts from /content/drive/My Drive/Resume Chatbot/resumes/general_engineer.json: 1548 characters of resume text.\n",
      "Candidate Daniel Roberts from /content/drive/My Drive/Resume Chatbot/resumes/general_engineer.json: Created 2 chunks.\n",
      "Candidate Rachel Adams from /content/drive/My Drive/Resume Chatbot/resumes/general_engineer.json: 1084 characters of resume text.\n",
      "Candidate Rachel Adams from /content/drive/My Drive/Resume Chatbot/resumes/general_engineer.json: Created 2 chunks.\n",
      "Candidate James Wilson from /content/drive/My Drive/Resume Chatbot/resumes/general_engineer.json: 1149 characters of resume text.\n",
      "Candidate James Wilson from /content/drive/My Drive/Resume Chatbot/resumes/general_engineer.json: Created 2 chunks.\n",
      "Candidate Sarah Carter from /content/drive/My Drive/Resume Chatbot/resumes/general_engineer.json: 940 characters of resume text.\n",
      "Candidate Sarah Carter from /content/drive/My Drive/Resume Chatbot/resumes/general_engineer.json: Created 1 chunks.\n",
      "Candidate Olivia Harris from /content/drive/My Drive/Resume Chatbot/resumes/general_engineer.json: 1076 characters of resume text.\n",
      "Candidate Olivia Harris from /content/drive/My Drive/Resume Chatbot/resumes/general_engineer.json: Created 2 chunks.\n",
      "Total number of documents created: 44\n"
     ]
    }
   ],
   "source": [
    "for json_path in json_paths:\n",
    "    print(f\"Checking file: {json_path}\")\n",
    "    if not os.path.exists(json_path):\n",
    "        print(f\"File does not exist: {json_path}\")\n",
    "        continue\n",
    "\n",
    "    with open(json_path, \"r\", encoding=\"utf-8\") as f:\n",
    "        candidates = json.load(f)\n",
    "        print(f\"Loaded {len(candidates)} candidates from {json_path}\")\n",
    "\n",
    "    for candidate_idx, candidate in enumerate(candidates, start=1):\n",
    "        candidate_name = candidate.get(\"name\", \"Unknown Candidate\")\n",
    "        resume_text = create_resume_text(candidate)\n",
    "\n",
    "        if not resume_text.strip():\n",
    "            print(f\"Candidate {candidate_name} from {json_path} has empty resume_text.\")\n",
    "        else:\n",
    "            print(f\"Candidate {candidate_name} from {json_path}: {len(resume_text)} characters of resume text.\")\n",
    "\n",
    "        chunks = text_splitter.split_text(resume_text)\n",
    "        print(f\"Candidate {candidate_name} from {json_path}: Created {len(chunks)} chunks.\")\n",
    "\n",
    "        for i, chunk in enumerate(chunks):\n",
    "            if not chunk.strip():\n",
    "                print(f\"Candidate {candidate_name}, chunk {i} is empty.\")\n",
    "            else:\n",
    "                metadata = {\n",
    "                    \"name\": candidate_name,\n",
    "                    \"chunk_id\": i\n",
    "                }\n",
    "                doc = Document(page_content=chunk, metadata=metadata)\n",
    "                documents.append(doc)\n",
    "\n",
    "print(f\"Total number of documents created: {len(documents)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 230,
     "status": "ok",
     "timestamp": 1733770922529,
     "user": {
      "displayName": "Aditya Asthana",
      "userId": "16260857847002908036"
     },
     "user_tz": 480
    },
    "id": "538JNygqmZAy",
    "outputId": "8e128006-10e1-4749-990a-f18c8f226181"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "44\n"
     ]
    }
   ],
   "source": [
    "#test\n",
    "print(len(documents))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "executionInfo": {
     "elapsed": 1714,
     "status": "ok",
     "timestamp": 1733770924979,
     "user": {
      "displayName": "Aditya Asthana",
      "userId": "16260857847002908036"
     },
     "user_tz": 480
    },
    "id": "5GD2yLpni9EZ"
   },
   "outputs": [],
   "source": [
    "embeddings = OpenAIEmbeddings(model=\"text-embedding-ada-002\")\n",
    "persist_directory = \"chroma_db_directory\"\n",
    "if not os.path.exists(persist_directory):\n",
    "    os.makedirs(persist_directory)\n",
    "\n",
    "vectorstore = Chroma.from_documents(\n",
    "    documents,\n",
    "    embedding=embeddings,\n",
    "    collection_name=\"candidate_resumes\",\n",
    "    persist_directory=persist_directory\n",
    ")\n",
    "vectorstore.persist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "executionInfo": {
     "elapsed": 1,
     "status": "ok",
     "timestamp": 1733770925139,
     "user": {
      "displayName": "Aditya Asthana",
      "userId": "16260857847002908036"
     },
     "user_tz": 480
    },
    "id": "sjqTo4i8jRZK"
   },
   "outputs": [],
   "source": [
    "recruiter_query = \"We need an expert in sales!\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "executionInfo": {
     "elapsed": 712,
     "status": "ok",
     "timestamp": 1733770927894,
     "user": {
      "displayName": "Aditya Asthana",
      "userId": "16260857847002908036"
     },
     "user_tz": 480
    },
    "id": "clGQvRuLjZWu"
   },
   "outputs": [],
   "source": [
    "retriever = vectorstore.as_retriever(search_kwargs={\"k\": 3})\n",
    "retrieved_docs = retriever.get_relevant_documents(recruiter_query)\n",
    "\n",
    "llm = ChatOpenAI(model_name='gpt-4', temperature=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 14568,
     "status": "ok",
     "timestamp": 1733770943369,
     "user": {
      "displayName": "Aditya Asthana",
      "userId": "16260857847002908036"
     },
     "user_tz": 480
    },
    "id": "3b5Wv6barjND",
    "outputId": "27e6f7e8-9a8d-457e-8c40-01356c04bcc4"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1. Candidate: Jordan Smith\n",
      "Relevant Resume Chunk: \n",
      "Profile: Experienced VP of Sales with a track record of building and leading high-performing sales teams.\n",
      "Experience:\n",
      "VP of Sales at Elite Enterprises (Mar 2015 - Present)\n",
      "- Increased annual revenue from $20 million to $50 million by implementing strategic sales initiatives.\n",
      "- Recruited and mentored a sales team of 50, fostering a high-performance culture.\n",
      "- Negotiated partnerships with key accounts, contributing to 40% of annual revenue.\n",
      "This chunk is relevant because Jordan Smith has a proven track record as a VP of Sales, demonstrating leadership and the ability to significantly increase revenue. His experience in recruiting and mentoring a large sales team also aligns with the job requirements.\n",
      "\n",
      "2. Candidate: Jordan Smith\n",
      "Relevant Resume Chunk: \n",
      "Profile: Experienced VP of Sales with a track record of building and leading high-performing sales teams.\n",
      "Experience:\n",
      "Regional Sales Manager at GrowthPartners (Jan 2013 - Feb 2015)\n",
      "- Managed sales operations across three regions, exceeding targets by 15% annually.\n",
      "- Led a team of 20 sales professionals, providing training and performance feedback.\n",
      "- Introduced CRM tools to streamline lead tracking and reporting.\n",
      "This chunk is relevant because Jordan Smith has demonstrated his ability to manage sales operations across multiple regions and lead a team of sales professionals. His experience with CRM tools and exceeding sales targets also aligns with the job requirements.\n",
      "\n",
      "3. Candidate: Sydney Brown\n",
      "Relevant Resume Chunk: \n",
      "Profile: Passionate Sales Manager with expertise in driving team success and exceeding revenue goals.\n",
      "Experience:\n",
      "Sales Manager at Visionary Ventures (Apr 2016 - Present)\n",
      "- Led a sales team of 15, achieving a 20% year-over-year growth in revenue.\n",
      "- Analyzed sales data to identify trends and optimize team strategies.\n",
      "- Implemented incentive programs that boosted team productivity by 30%.\n",
      "This chunk is relevant because Sydney Brown has experience as a Sales Manager, leading a team and achieving significant growth in revenue. Her skills in analyzing sales data and implementing incentive programs also align with the job requirements.\n"
     ]
    }
   ],
   "source": [
    "system_prompt = \"\"\"You are a helpful assistant that identifies top candidates given a job description.\n",
    "Given the recruiter's query and the retrieved resume chunks, list the top 3 candidates.\n",
    "For each candidate, provide:\n",
    "1. The candidate's name\n",
    "2. The specific part of their resume (the chunk) that best matches the job description.\n",
    "Explain why this chunk is relevant to the recruiter's query.\"\"\"\n",
    "\n",
    "retrieved_text = \"\"\n",
    "for i, doc in enumerate(retrieved_docs, start=1):\n",
    "    candidate_name = doc.metadata[\"name\"]\n",
    "    chunk_content = doc.page_content\n",
    "    retrieved_text += f\"Match #{i} - Candidate: {candidate_name}\\nResume Chunk:\\n{chunk_content}\\n\\n\"\n",
    "\n",
    "final_prompt = f\"\"\"\n",
    "The recruiter query: \"{recruiter_query}\"\n",
    "\n",
    "The following candidate resume sections have been retrieved as the most relevant:\n",
    "\n",
    "{retrieved_text}\n",
    "\n",
    "Please respond with the top 3 candidates that best fit the job description.\n",
    "For each candidate, state their name and show the relevant portion of their resume above.\n",
    "Explain how that portion aligns with the job requirements.\n",
    "\"\"\"\n",
    "from langchain.schema import SystemMessage, HumanMessage\n",
    "\n",
    "response = llm([\n",
    "    SystemMessage(content=system_prompt),\n",
    "    HumanMessage(content=final_prompt)\n",
    "])\n",
    "\n",
    "print(response.content)"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "authorship_tag": "ABX9TyOmKKKiGjhTghEb6lXdIKIa",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
